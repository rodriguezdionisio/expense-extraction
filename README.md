# Expense - **ğŸ“Š ExtracciÃ³n Inteligente**: Sistema con logging para prevenir duplicados automÃ¡ticamente
- **ğŸ—ï¸ Arquitectura Simplificada**: CÃ³digo optimizado reducido en 28% manteniendo funcionalidad completa
- **ğŸ“ Estructura Data Warehouse**: Tablas fact separadas (`fact_expenses`, `fact_expense_orders`)
- **ğŸ—‚ï¸ Particionado Hive-Style**: Estructura `clean/fact_*/date=YYYY-MM-DD/`
- **ğŸš€ Formato Parquet**: Archivos de alto rendimiento con compresiÃ³n y tipado optimizado
- **ğŸ” AutenticaciÃ³n Segura**: IntegraciÃ³n con Google Cloud Secret Manager
- **ğŸ“ Sistema de Logging**: PrevenciÃ³n automÃ¡tica de extracciones duplicadas
- **ğŸ› ï¸ Scripts CLI Simplificados**: Interfaces de lÃ­nea de comandos fÃ¡ciles de usarion & Processing System

Sistema optimizado de extracciÃ³n y procesamiento de gastos desde la API de Fudo con transformaciÃ³n a Parquet estructurado y prevenciÃ³n de duplicados.

## DescripciÃ³n

Este proyecto extrae datos de gastos (expenses) desde la API REST de Fudo, los procesa y los convierte en archivos Parquet particionados por fecha para anÃ¡lisis de datos. El sistema ha sido completamente optimizado con arquitectura simplificada, sistema de logging para prevenir duplicados, y estructura de datos tipo data warehouse con formato Parquet de alto rendimiento.

## CaracterÃ­sticas Principales

- **ï¿½ ExtracciÃ³n Inteligente**: Sistema con logging para prevenir duplicados automÃ¡ticamente
- **ğŸ—ï¸ Arquitectura Simplificada**: CÃ³digo optimizado reducido en 28% manteniendo funcionalidad completa
- **ğŸ“ Estructura Data Warehouse**: Tablas fact separadas (`fact_expenses`, `fact_expense_orders`)
- **ï¿½ï¸ Particionado Hive-Style**: Estructura `clean/fact_*/date=YYYY-MM-DD/`
- **ğŸ” AutenticaciÃ³n Segura**: IntegraciÃ³n con Google Cloud Secret Manager
- **ï¿½ Sistema de Logging**: PrevenciÃ³n automÃ¡tica de extracciones duplicadas
- **ğŸš€ Scripts CLI Simplificados**: Interfaces de lÃ­nea de comandos fÃ¡ciles de usar

## Estructura del Proyecto

```
expense-extraction/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ credentials.json          # Credenciales de Google Cloud
â”œâ”€â”€ utils/                        # MÃ³dulos de utilidades optimizados
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ env_config.py            # ConfiguraciÃ³n de variables de entorno
â”‚   â”œâ”€â”€ gcp.py                   # Utilidades de Google Cloud
â”‚   â””â”€â”€ logger.py                # Sistema de logging
â”œâ”€â”€ raw/                         # Archivos JSON individuales extraÃ­dos
â”‚   â”œâ”€â”€ expense_1.json
â”‚   â”œâ”€â”€ expense_2.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ clean/                       # Datos procesados en estructura data warehouse
â”‚   â”œâ”€â”€ fact_expenses/           # Tabla principal de gastos
â”‚   â”‚   â”œâ”€â”€ date=2019-10-27/
â”‚   â”‚   â”‚   â””â”€â”€ fact_expenses.parquet
â”‚   â”‚   â”œâ”€â”€ date=2020-01-04/
â”‚   â”‚   â”‚   â””â”€â”€ fact_expenses.parquet
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ fact_expense_orders/     # Tabla de Ã³rdenes/items de gastos
â”‚       â”œâ”€â”€ date=2019-10-27/
â”‚       â”‚   â””â”€â”€ fact_expense_orders.parquet
â”‚       â”œâ”€â”€ date=2020-01-04/
â”‚       â”‚   â””â”€â”€ fact_expense_orders.parquet
â”‚       â””â”€â”€ ...
â”œâ”€â”€ logs/                        # Sistema de logging para duplicados
â”‚   â””â”€â”€ extracted_expenses_log.txt
â”œâ”€â”€ expense_extractor.py         # Sistema de extracciÃ³n optimizado
â”œâ”€â”€ expense_processor.py         # Sistema de procesamiento optimizado
â”œâ”€â”€ run_extraction.py           # Script CLI para extracciÃ³n
â”œâ”€â”€ run_processing.py           # Script CLI para procesamiento
â”œâ”€â”€ requirements.txt            # Dependencias
â””â”€â”€ README.md                   # Este archivo
```

## InstalaciÃ³n

1. **Clonar el repositorio**:
```bash
git clone <repository-url>
cd expense-extraction
```

2. **Crear entorno virtual**:
```bash
python -m venv .venv
source .venv/bin/activate  # En Linux/Mac
# .venv\Scripts\activate  # En Windows
```

3. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno**:
```bash
cp .env.example .env
# Editar .env con tus valores
```

5. **Configurar credenciales de Google Cloud**:
   - Crear proyecto en Google Cloud
   - Habilitar Secret Manager API
   - Crear service account y descargar credenciales
   - Colocar credenciales en `config/credentials.json`

## ConfiguraciÃ³n

### Variables de Entorno (.env)

```env
# Google Cloud
GCP_PROJECT_ID=tu-proyecto-gcp-id
GOOGLE_APPLICATION_CREDENTIALS=config/credentials.json

# Fudo API (almacenados en Google Cloud Secret Manager)
# fudo-api-key: Tu API key de Fudo
# fudo-api-secret: Tu API secret de Fudo

# ConfiguraciÃ³n de extracciÃ³n
EXPENSE_EXTRACTION_MODE=maintenance
EXPENSE_START_ID=500
```

## Uso del Sistema

### 1. ExtracciÃ³n de Datos

El sistema optimizado incluye prevenciÃ³n automÃ¡tica de duplicados mediante sistema de logging.

#### ExtracciÃ³n por Rango
```bash
# Extraer IDs especÃ­ficos (ej: primeros 20)
python run_extraction.py 1 20

# Extraer un solo ID
python run_extraction.py 25 25

# Extraer siguiente lote
python run_extraction.py 21 40
```

### 2. Procesamiento a CSV

#### Procesamiento por Rango (Recomendado)
```bash
# Procesar los mismos IDs extraÃ­dos (ej: 1-20)
python run_processing.py 1 20

# Procesar un solo expense
python run_processing.py 25 25

# Procesar lote completo
python run_processing.py 21 40
```

### 3. Flujo Completo TÃ­pico

```bash
# 1. Extraer datos desde API
python run_extraction.py 1 20

# 2. Procesar a tablas fact
python run_processing.py 1 20

# 3. Continuar con siguiente lote
python run_extraction.py 21 40
python run_processing.py 21 40
```

## Estructura de Archivos de Salida

### Estructura Data Warehouse

El sistema genera dos tablas fact separadas organizadas por fechas:

```
clean/
â”œâ”€â”€ fact_expenses/              # Tabla principal de gastos
â”‚   â”œâ”€â”€ date=2019-10-27/
â”‚   â”‚   â””â”€â”€ fact_expenses.csv
â”‚   â”œâ”€â”€ date=2020-01-04/
â”‚   â”‚   â””â”€â”€ fact_expenses.csv
â”‚   â””â”€â”€ ...
â””â”€â”€ fact_expense_orders/        # Tabla de Ã³rdenes/items
    â”œâ”€â”€ date=2019-10-27/
    â”‚   â””â”€â”€ fact_expense_orders.csv
    â”œâ”€â”€ date=2020-01-04/
    â”‚   â””â”€â”€ fact_expense_orders.csv
    â””â”€â”€ ...
```

### Archivos CSV Generados

#### `fact_expenses.csv` - Datos principales de gastos
```csv
expense_key,expense_amount,cancelled,expense_date_key,payment_date_key,due_date_key,created_date_key,created_time_key,expense_note,receipt_number,use_in_cash_count,cashregister_key,paymentmethod_key,provider_key,receipttype_key,user_key
1,1500.0,False,20200104,20200110,20200115,20200104,1430,Compra materiales,001-123,True,1,2,45,1,7
```

#### `fact_expense_orders.csv` - LÃ­neas de detalle (expense items)
```csv
expense_order_key,expense_key,cancelled,item_detail,item_price,item_quantity,product_key,product_name,product_cost,product_unit,ingredient_key,ingredient_name,ingredient_cost,ingredient_unit
456,1,False,Harina 000,850.0,2.0,789,Harina 000 x 1kg,800.0,kg,101,Harina 000,800.0,kg
```

## Transformaciones Aplicadas

### Renombrado de Columnas
- `expense_id` â†’ `expense_key` (int64)
- `amount` â†’ `expense_amount` (float64)
- `canceled` â†’ `cancelled` (bool)
- `date` â†’ `expense_date_key` (int64, formato YYYYMMDD)
- `created_at` â†’ `created_date_key`, `created_time_key` (int64)
- `description` â†’ `expense_note` (string)
- IDs de relaciones â†’ `*_key` (int64)

### TransformaciÃ³n de Expense Items
- `expense_item_id` â†’ `expense_order_key` (int64)
- `expense_id` â†’ `expense_key` (int64, clave forÃ¡nea)
- `detail` â†’ `item_detail` (string)
- `price` â†’ `item_price` (float64)
- `quantity` â†’ `item_quantity` (float64)
- Datos de productos e ingredientes incluidos con prefijos

### Sistema de Logging
- **PrevenciÃ³n de Duplicados**: `logs/extracted_expenses_log.txt`
- **VerificaciÃ³n AutomÃ¡tica**: El sistema verifica IDs ya extraÃ­dos
- **InicializaciÃ³n Inteligente**: Detecta archivos existentes al inicio

### Particionado por Fecha

Los archivos se organizan en estructura Hive-style por tablas fact:
```
clean/
â”œâ”€â”€ fact_expenses/
â”‚   â”œâ”€â”€ date=2019-10-27/
â”‚   â”‚   â””â”€â”€ fact_expenses.parquet      # Expenses de esa fecha
â”‚   â”œâ”€â”€ date=2020-01-04/
â”‚   â”‚   â””â”€â”€ fact_expenses.parquet
â”‚   â””â”€â”€ ...
â””â”€â”€ fact_expense_orders/
    â”œâ”€â”€ date=2019-10-27/
    â”‚   â””â”€â”€ fact_expense_orders.parquet # Items de esa fecha
    â”œâ”€â”€ date=2020-01-04/
    â”‚   â””â”€â”€ fact_expense_orders.parquet
    â””â”€â”€ ...
```

### Archivos Parquet Generados

#### `fact_expenses.parquet` - Datos principales de gastos
Columnas optimizadas con tipos de datos eficientes:
- `expense_key` (int64): Clave primaria del gasto
- `expense_amount` (float64): Monto del gasto
- `cancelled` (bool): Estado de cancelaciÃ³n
- `expense_date_key` (int64): Fecha del gasto (YYYYMMDD)
- `payment_date_key`, `due_date_key`, `created_date_key` (int64): Fechas relacionadas
- `created_time_key` (int64): Hora de creaciÃ³n (HHMM)
- Claves forÃ¡neas: `cashregister_key`, `paymentmethod_key`, `provider_key`, etc.

#### `fact_expense_orders.parquet` - LÃ­neas de detalle (expense items)
Columnas optimizadas para anÃ¡lisis de items:
- `expense_order_key` (int64): Clave primaria del item
- `expense_key` (int64): Clave forÃ¡nea al expense principal
- `item_detail` (string): DescripciÃ³n del item
- `item_price`, `item_quantity` (float64): Precio y cantidad
- Datos de productos e ingredientes con prefijos optimizados

## API Reference

### ExpenseExtractor (Optimizado)
```python
from expense_extractor import ExpenseExtractor

extractor = ExpenseExtractor()

# Inicializar sistema de logging
extractor.initialize_log_from_existing_files()

# Extraer rango con prevenciÃ³n de duplicados
expenses, count = extractor.extract_range(1, 20)
```

### ExpenseProcessor (Optimizado)
```python
from expense_processor import ExpenseProcessor

processor = ExpenseProcessor()

# Procesar rango especÃ­fico
processor.process_range(1, 20)
```

## Optimizaciones del Sistema

- **28% ReducciÃ³n de CÃ³digo**: De 973 a 698 lÃ­neas manteniendo funcionalidad completa
- **Arquitectura Simplificada**: EliminaciÃ³n de cÃ³digo duplicado y no utilizado
- **Sistema de Logging**: PrevenciÃ³n automÃ¡tica de duplicados
- **Scripts CLI Mejorados**: Interfaces mÃ¡s simples y directas
- **Estructura Data Warehouse**: SeparaciÃ³n clara de tablas fact
- **Formato Parquet Optimizado**: 
  - CompresiÃ³n automÃ¡tica para menor uso de espacio
  - Tipado de datos optimizado para consultas rÃ¡pidas
  - Compatible con herramientas de anÃ¡lisis modernas (Pandas, Spark, etc.)
  - Metadatos incluidos para mejor rendimiento

## Ventajas del Formato Parquet

- **ğŸš€ Rendimiento**: Consultas hasta 10x mÃ¡s rÃ¡pidas que CSV
- **ğŸ’¾ CompresiÃ³n**: Archivos 50-80% mÃ¡s pequeÃ±os
- **ğŸ¯ Tipado**: PreservaciÃ³n de tipos de datos (int64, float64, bool, string)
- **ğŸ“Š Compatibilidad**: Soporte nativo en Pandas, Spark, PowerBI, Tableau
- **ğŸ” Filtrado**: Pushdown predicates para consultas eficientes
- **ğŸ“ˆ Columnar**: Almacenamiento optimizado para anÃ¡lisis

## Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.
