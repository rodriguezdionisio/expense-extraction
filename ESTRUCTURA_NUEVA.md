# Nueva Estructura de Datos - Data Lake

## ğŸ“ Estructura de Carpetas

### **Raw Data (Datos en Bruto)**
```
raw/
â”œâ”€â”€ expense_1.json
â”œâ”€â”€ expense_2.json
â”œâ”€â”€ expense_3.json
â””â”€â”€ ...
```
- **PropÃ³sito**: Almacenar datos extraÃ­dos directamente de la API de Fudo
- **Formato**: JSON individual por expense
- **Fuente**: `expense_extractor.py` â†’ `run_extraction.py`

### **Clean Data (Datos Procesados)**
```
clean/
â”œâ”€â”€ fact_expenses/
â”‚   â”œâ”€â”€ date=2019-10-27/
â”‚   â”‚   â””â”€â”€ fact_expenses.csv
â”‚   â”œâ”€â”€ date=2019-11-06/
â”‚   â”‚   â””â”€â”€ fact_expenses.csv
â”‚   â””â”€â”€ date=YYYY-MM-DD/
â”‚       â””â”€â”€ fact_expenses.csv
â””â”€â”€ fact_expense_orders/
    â”œâ”€â”€ date=2019-10-27/
    â”‚   â””â”€â”€ fact_expense_orders.csv
    â”œâ”€â”€ date=2019-11-06/
    â”‚   â””â”€â”€ fact_expense_orders.csv
    â””â”€â”€ date=YYYY-MM-DD/
        â””â”€â”€ fact_expense_orders.csv
```

## ğŸ“Š Tablas de Datos

### **fact_expenses.csv**
- **UbicaciÃ³n**: `clean/fact_expenses/date=YYYY-MM-DD/`
- **Contenido**: Datos principales de expenses
- **Particionado**: Por fecha de creaciÃ³n (created_at)
- **Formato**: CSV con headers

### **fact_expense_orders.csv**
- **UbicaciÃ³n**: `clean/fact_expense_orders/date=YYYY-MM-DD/`
- **Contenido**: Items/productos dentro de cada expense
- **Particionado**: Por fecha de creaciÃ³n del expense padre
- **Formato**: CSV con headers

## ğŸ”„ Flujo de Datos

1. **ExtracciÃ³n**: API Fudo â†’ `raw/expense_X.json`
2. **Procesamiento**: `raw/*.json` â†’ `clean/fact_*/date=YYYY-MM-DD/*.csv`

## ğŸš€ Comandos de Uso

### Extraer datos
```bash
python run_extraction.py <start_id> <end_id>
# Ejemplo: python run_extraction.py 1 100
```

### Procesar datos
```bash
python run_processing.py <start_id> <end_id>
# Ejemplo: python run_processing.py 1 100
```

## ğŸ“ˆ Ventajas de la Nueva Estructura

1. **SeparaciÃ³n Clara**: Raw vs Clean data
2. **Escalabilidad**: Particionado por fecha para consultas eficientes
3. **Tablas Fact**: SeparaciÃ³n lÃ³gica entre expenses y expense orders
4. **EstÃ¡ndar Data Lake**: Estructura tipo Hive con `date=YYYY-MM-DD`
5. **Flexibilidad**: FÃ¡cil integraciÃ³n con herramientas de Big Data

## âš ï¸ MigraciÃ³n Completada

- âœ… `extraction_data/` â†’ `raw/`
- âœ… `processed_data/` â†’ `clean/`
- âœ… Archivos CSV separados en `fact_expenses/` y `fact_expense_orders/`
- âœ… Mantenimiento de estructura de particionado por fecha
